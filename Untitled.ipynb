{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/938] [D loss: 0.446711] [G loss: 0.920681]\n",
      "[Epoch 0/200] [Batch 1/938] [D loss: 0.229827] [G loss: 0.895644]\n",
      "[Epoch 0/200] [Batch 2/938] [D loss: 0.077203] [G loss: 0.870859]\n",
      "[Epoch 0/200] [Batch 3/938] [D loss: 0.014316] [G loss: 0.851695]\n",
      "[Epoch 0/200] [Batch 4/938] [D loss: 0.035093] [G loss: 0.838239]\n",
      "[Epoch 0/200] [Batch 5/938] [D loss: 0.016536] [G loss: 0.830048]\n",
      "[Epoch 0/200] [Batch 6/938] [D loss: 0.011528] [G loss: 0.836413]\n",
      "[Epoch 0/200] [Batch 7/938] [D loss: 0.015345] [G loss: 0.837748]\n",
      "[Epoch 0/200] [Batch 8/938] [D loss: 0.013231] [G loss: 0.824372]\n",
      "[Epoch 0/200] [Batch 9/938] [D loss: 0.014244] [G loss: 0.817372]\n",
      "[Epoch 0/200] [Batch 10/938] [D loss: 0.016516] [G loss: 0.806053]\n",
      "[Epoch 0/200] [Batch 11/938] [D loss: 0.014051] [G loss: 0.802717]\n",
      "[Epoch 0/200] [Batch 12/938] [D loss: 0.016418] [G loss: 0.800505]\n",
      "[Epoch 0/200] [Batch 13/938] [D loss: 0.014723] [G loss: 0.779772]\n",
      "[Epoch 0/200] [Batch 14/938] [D loss: 0.013323] [G loss: 0.780775]\n",
      "[Epoch 0/200] [Batch 15/938] [D loss: 0.014057] [G loss: 0.766550]\n",
      "[Epoch 0/200] [Batch 16/938] [D loss: 0.015015] [G loss: 0.751211]\n",
      "[Epoch 0/200] [Batch 17/938] [D loss: 0.017248] [G loss: 0.732585]\n",
      "[Epoch 0/200] [Batch 18/938] [D loss: 0.015838] [G loss: 0.741294]\n",
      "[Epoch 0/200] [Batch 19/938] [D loss: 0.020342] [G loss: 0.708103]\n",
      "[Epoch 0/200] [Batch 20/938] [D loss: 0.022620] [G loss: 0.727593]\n",
      "[Epoch 0/200] [Batch 21/938] [D loss: 0.020045] [G loss: 0.703155]\n",
      "[Epoch 0/200] [Batch 22/938] [D loss: 0.020807] [G loss: 0.704106]\n",
      "[Epoch 0/200] [Batch 23/938] [D loss: 0.021883] [G loss: 0.690370]\n",
      "[Epoch 0/200] [Batch 24/938] [D loss: 0.023598] [G loss: 0.719400]\n",
      "[Epoch 0/200] [Batch 25/938] [D loss: 0.017763] [G loss: 0.744262]\n",
      "[Epoch 0/200] [Batch 26/938] [D loss: 0.018007] [G loss: 0.754400]\n",
      "[Epoch 0/200] [Batch 27/938] [D loss: 0.016425] [G loss: 0.805672]\n",
      "[Epoch 0/200] [Batch 28/938] [D loss: 0.015137] [G loss: 0.809991]\n",
      "[Epoch 0/200] [Batch 29/938] [D loss: 0.013550] [G loss: 0.916273]\n",
      "[Epoch 0/200] [Batch 30/938] [D loss: 0.027008] [G loss: 0.767369]\n",
      "[Epoch 0/200] [Batch 31/938] [D loss: 0.053235] [G loss: 0.975984]\n",
      "[Epoch 0/200] [Batch 32/938] [D loss: 0.039886] [G loss: 0.636518]\n",
      "[Epoch 0/200] [Batch 33/938] [D loss: 0.030907] [G loss: 0.663567]\n",
      "[Epoch 0/200] [Batch 34/938] [D loss: 0.031730] [G loss: 0.756504]\n",
      "[Epoch 0/200] [Batch 35/938] [D loss: 0.023043] [G loss: 0.714219]\n",
      "[Epoch 0/200] [Batch 36/938] [D loss: 0.022432] [G loss: 0.757601]\n",
      "[Epoch 0/200] [Batch 37/938] [D loss: 0.026124] [G loss: 0.938897]\n",
      "[Epoch 0/200] [Batch 38/938] [D loss: 0.086826] [G loss: 0.462557]\n",
      "[Epoch 0/200] [Batch 39/938] [D loss: 0.122484] [G loss: 1.077855]\n",
      "[Epoch 0/200] [Batch 40/938] [D loss: 0.070875] [G loss: 0.447780]\n",
      "[Epoch 0/200] [Batch 41/938] [D loss: 0.069423] [G loss: 0.482266]\n",
      "[Epoch 0/200] [Batch 42/938] [D loss: 0.054562] [G loss: 0.582874]\n",
      "[Epoch 0/200] [Batch 43/938] [D loss: 0.037660] [G loss: 0.623461]\n",
      "[Epoch 0/200] [Batch 44/938] [D loss: 0.035419] [G loss: 0.649243]\n",
      "[Epoch 0/200] [Batch 45/938] [D loss: 0.035077] [G loss: 0.669359]\n",
      "[Epoch 0/200] [Batch 46/938] [D loss: 0.025542] [G loss: 0.745435]\n",
      "[Epoch 0/200] [Batch 47/938] [D loss: 0.029245] [G loss: 0.784604]\n",
      "[Epoch 0/200] [Batch 48/938] [D loss: 0.061301] [G loss: 0.544615]\n",
      "[Epoch 0/200] [Batch 49/938] [D loss: 0.322641] [G loss: 1.312423]\n",
      "[Epoch 0/200] [Batch 50/938] [D loss: 0.360914] [G loss: 0.129547]\n",
      "[Epoch 0/200] [Batch 51/938] [D loss: 0.110969] [G loss: 0.505560]\n",
      "[Epoch 0/200] [Batch 52/938] [D loss: 0.158020] [G loss: 0.562074]\n",
      "[Epoch 0/200] [Batch 53/938] [D loss: 0.129289] [G loss: 0.456582]\n",
      "[Epoch 0/200] [Batch 54/938] [D loss: 0.114562] [G loss: 0.346082]\n",
      "[Epoch 0/200] [Batch 55/938] [D loss: 0.117308] [G loss: 0.351965]\n",
      "[Epoch 0/200] [Batch 56/938] [D loss: 0.100947] [G loss: 0.427780]\n",
      "[Epoch 0/200] [Batch 57/938] [D loss: 0.085013] [G loss: 0.517219]\n",
      "[Epoch 0/200] [Batch 58/938] [D loss: 0.085696] [G loss: 0.512241]\n",
      "[Epoch 0/200] [Batch 59/938] [D loss: 0.073796] [G loss: 0.515880]\n",
      "[Epoch 0/200] [Batch 60/938] [D loss: 0.061614] [G loss: 0.579735]\n",
      "[Epoch 0/200] [Batch 61/938] [D loss: 0.070101] [G loss: 0.507810]\n",
      "[Epoch 0/200] [Batch 62/938] [D loss: 0.262859] [G loss: 1.322875]\n",
      "[Epoch 0/200] [Batch 63/938] [D loss: 1.665270] [G loss: 0.330349]\n",
      "[Epoch 0/200] [Batch 64/938] [D loss: 0.208493] [G loss: 0.772672]\n",
      "[Epoch 0/200] [Batch 65/938] [D loss: 0.343922] [G loss: 0.963558]\n",
      "[Epoch 0/200] [Batch 66/938] [D loss: 0.266473] [G loss: 0.692056]\n",
      "[Epoch 0/200] [Batch 67/938] [D loss: 0.194942] [G loss: 0.477467]\n",
      "[Epoch 0/200] [Batch 68/938] [D loss: 0.168526] [G loss: 0.333286]\n",
      "[Epoch 0/200] [Batch 69/938] [D loss: 0.179288] [G loss: 0.232178]\n",
      "[Epoch 0/200] [Batch 70/938] [D loss: 0.146095] [G loss: 0.373601]\n",
      "[Epoch 0/200] [Batch 71/938] [D loss: 0.145757] [G loss: 0.422902]\n",
      "[Epoch 0/200] [Batch 72/938] [D loss: 0.116339] [G loss: 0.488168]\n",
      "[Epoch 0/200] [Batch 73/938] [D loss: 0.110180] [G loss: 0.405348]\n",
      "[Epoch 0/200] [Batch 74/938] [D loss: 0.094901] [G loss: 0.561293]\n",
      "[Epoch 0/200] [Batch 75/938] [D loss: 0.125452] [G loss: 0.380711]\n",
      "[Epoch 0/200] [Batch 76/938] [D loss: 0.138369] [G loss: 0.578643]\n",
      "[Epoch 0/200] [Batch 77/938] [D loss: 0.201121] [G loss: 0.197777]\n",
      "[Epoch 0/200] [Batch 78/938] [D loss: 0.481169] [G loss: 1.391288]\n",
      "[Epoch 0/200] [Batch 79/938] [D loss: 0.490721] [G loss: 0.029719]\n",
      "[Epoch 0/200] [Batch 80/938] [D loss: 0.237843] [G loss: 0.172343]\n",
      "[Epoch 0/200] [Batch 81/938] [D loss: 0.217404] [G loss: 0.440156]\n",
      "[Epoch 0/200] [Batch 82/938] [D loss: 0.208942] [G loss: 0.499608]\n",
      "[Epoch 0/200] [Batch 83/938] [D loss: 0.170828] [G loss: 0.424307]\n",
      "[Epoch 0/200] [Batch 84/938] [D loss: 0.164972] [G loss: 0.297833]\n",
      "[Epoch 0/200] [Batch 85/938] [D loss: 0.138640] [G loss: 0.341027]\n",
      "[Epoch 0/200] [Batch 86/938] [D loss: 0.118830] [G loss: 0.391899]\n",
      "[Epoch 0/200] [Batch 87/938] [D loss: 0.111125] [G loss: 0.480034]\n",
      "[Epoch 0/200] [Batch 88/938] [D loss: 0.123855] [G loss: 0.417724]\n",
      "[Epoch 0/200] [Batch 89/938] [D loss: 0.130129] [G loss: 0.437887]\n",
      "[Epoch 0/200] [Batch 90/938] [D loss: 0.126378] [G loss: 0.438167]\n",
      "[Epoch 0/200] [Batch 91/938] [D loss: 0.141538] [G loss: 0.407133]\n",
      "[Epoch 0/200] [Batch 92/938] [D loss: 0.165713] [G loss: 0.351597]\n",
      "[Epoch 0/200] [Batch 93/938] [D loss: 0.133280] [G loss: 0.522366]\n",
      "[Epoch 0/200] [Batch 94/938] [D loss: 0.204978] [G loss: 0.216166]\n",
      "[Epoch 0/200] [Batch 95/938] [D loss: 0.521517] [G loss: 1.590826]\n",
      "[Epoch 0/200] [Batch 96/938] [D loss: 0.390366] [G loss: 0.041788]\n",
      "[Epoch 0/200] [Batch 97/938] [D loss: 0.154393] [G loss: 0.375372]\n",
      "[Epoch 0/200] [Batch 98/938] [D loss: 0.161349] [G loss: 0.606407]\n",
      "[Epoch 0/200] [Batch 99/938] [D loss: 0.115850] [G loss: 0.498742]\n",
      "[Epoch 0/200] [Batch 100/938] [D loss: 0.109147] [G loss: 0.364156]\n",
      "[Epoch 0/200] [Batch 101/938] [D loss: 0.082696] [G loss: 0.419920]\n",
      "[Epoch 0/200] [Batch 102/938] [D loss: 0.094381] [G loss: 0.632389]\n",
      "[Epoch 0/200] [Batch 103/938] [D loss: 0.086833] [G loss: 0.526345]\n",
      "[Epoch 0/200] [Batch 104/938] [D loss: 0.081989] [G loss: 0.524054]\n",
      "[Epoch 0/200] [Batch 105/938] [D loss: 0.099845] [G loss: 0.640590]\n",
      "[Epoch 0/200] [Batch 106/938] [D loss: 0.128167] [G loss: 0.369658]\n",
      "[Epoch 0/200] [Batch 107/938] [D loss: 0.221183] [G loss: 1.165234]\n",
      "[Epoch 0/200] [Batch 108/938] [D loss: 0.482844] [G loss: 0.018217]\n",
      "[Epoch 0/200] [Batch 109/938] [D loss: 0.296503] [G loss: 1.317295]\n",
      "[Epoch 0/200] [Batch 110/938] [D loss: 0.157585] [G loss: 0.707722]\n",
      "[Epoch 0/200] [Batch 111/938] [D loss: 0.160231] [G loss: 0.260863]\n",
      "[Epoch 0/200] [Batch 112/938] [D loss: 0.143328] [G loss: 0.282979]\n",
      "[Epoch 0/200] [Batch 113/938] [D loss: 0.108578] [G loss: 0.594167]\n",
      "[Epoch 0/200] [Batch 114/938] [D loss: 0.078177] [G loss: 0.688745]\n",
      "[Epoch 0/200] [Batch 115/938] [D loss: 0.081037] [G loss: 0.517980]\n",
      "[Epoch 0/200] [Batch 116/938] [D loss: 0.076179] [G loss: 0.461234]\n",
      "[Epoch 0/200] [Batch 117/938] [D loss: 0.090713] [G loss: 0.668350]\n",
      "[Epoch 0/200] [Batch 118/938] [D loss: 0.121203] [G loss: 0.402819]\n",
      "[Epoch 0/200] [Batch 119/938] [D loss: 0.115274] [G loss: 0.849813]\n",
      "[Epoch 0/200] [Batch 120/938] [D loss: 0.265491] [G loss: 0.144522]\n",
      "[Epoch 0/200] [Batch 121/938] [D loss: 0.400572] [G loss: 1.591923]\n",
      "[Epoch 0/200] [Batch 122/938] [D loss: 0.345807] [G loss: 0.060009]\n",
      "[Epoch 0/200] [Batch 123/938] [D loss: 0.166617] [G loss: 0.285561]\n",
      "[Epoch 0/200] [Batch 124/938] [D loss: 0.158682] [G loss: 0.672283]\n",
      "[Epoch 0/200] [Batch 125/938] [D loss: 0.128311] [G loss: 0.624230]\n",
      "[Epoch 0/200] [Batch 126/938] [D loss: 0.113431] [G loss: 0.382518]\n",
      "[Epoch 0/200] [Batch 127/938] [D loss: 0.090056] [G loss: 0.465922]\n",
      "[Epoch 0/200] [Batch 128/938] [D loss: 0.090846] [G loss: 0.642959]\n",
      "[Epoch 0/200] [Batch 129/938] [D loss: 0.093589] [G loss: 0.480423]\n",
      "[Epoch 0/200] [Batch 130/938] [D loss: 0.101642] [G loss: 0.768780]\n",
      "[Epoch 0/200] [Batch 131/938] [D loss: 0.145117] [G loss: 0.323243]\n",
      "[Epoch 0/200] [Batch 132/938] [D loss: 0.174990] [G loss: 0.922804]\n",
      "[Epoch 0/200] [Batch 133/938] [D loss: 0.278682] [G loss: 0.073660]\n",
      "[Epoch 0/200] [Batch 134/938] [D loss: 0.200641] [G loss: 1.112019]\n",
      "[Epoch 0/200] [Batch 135/938] [D loss: 0.137611] [G loss: 0.321769]\n",
      "[Epoch 0/200] [Batch 136/938] [D loss: 0.100356] [G loss: 0.433883]\n",
      "[Epoch 0/200] [Batch 137/938] [D loss: 0.120535] [G loss: 0.680158]\n",
      "[Epoch 0/200] [Batch 138/938] [D loss: 0.127875] [G loss: 0.348834]\n",
      "[Epoch 0/200] [Batch 139/938] [D loss: 0.110603] [G loss: 0.541703]\n",
      "[Epoch 0/200] [Batch 140/938] [D loss: 0.109701] [G loss: 0.579894]\n",
      "[Epoch 0/200] [Batch 141/938] [D loss: 0.156090] [G loss: 0.274847]\n",
      "[Epoch 0/200] [Batch 142/938] [D loss: 0.151861] [G loss: 0.611416]\n",
      "[Epoch 0/200] [Batch 143/938] [D loss: 0.214000] [G loss: 0.219768]\n",
      "[Epoch 0/200] [Batch 144/938] [D loss: 0.218322] [G loss: 0.830103]\n",
      "[Epoch 0/200] [Batch 145/938] [D loss: 0.256715] [G loss: 0.129106]\n",
      "[Epoch 0/200] [Batch 146/938] [D loss: 0.127239] [G loss: 0.634531]\n",
      "[Epoch 0/200] [Batch 147/938] [D loss: 0.111044] [G loss: 0.626850]\n",
      "[Epoch 0/200] [Batch 148/938] [D loss: 0.104760] [G loss: 0.390232]\n",
      "[Epoch 0/200] [Batch 149/938] [D loss: 0.090819] [G loss: 0.505603]\n",
      "[Epoch 0/200] [Batch 150/938] [D loss: 0.098888] [G loss: 0.689135]\n",
      "[Epoch 0/200] [Batch 151/938] [D loss: 0.108100] [G loss: 0.397688]\n",
      "[Epoch 0/200] [Batch 152/938] [D loss: 0.086709] [G loss: 0.621414]\n",
      "[Epoch 0/200] [Batch 153/938] [D loss: 0.099842] [G loss: 0.516540]\n",
      "[Epoch 0/200] [Batch 154/938] [D loss: 0.107546] [G loss: 0.461904]\n",
      "[Epoch 0/200] [Batch 155/938] [D loss: 0.133399] [G loss: 0.528796]\n",
      "[Epoch 0/200] [Batch 156/938] [D loss: 0.143238] [G loss: 0.311719]\n",
      "[Epoch 0/200] [Batch 157/938] [D loss: 0.151954] [G loss: 0.705396]\n",
      "[Epoch 0/200] [Batch 158/938] [D loss: 0.284540] [G loss: 0.094073]\n",
      "[Epoch 0/200] [Batch 159/938] [D loss: 0.307565] [G loss: 1.170232]\n",
      "[Epoch 0/200] [Batch 160/938] [D loss: 0.265769] [G loss: 0.123074]\n",
      "[Epoch 0/200] [Batch 161/938] [D loss: 0.134442] [G loss: 0.433780]\n",
      "[Epoch 0/200] [Batch 162/938] [D loss: 0.135619] [G loss: 0.757148]\n",
      "[Epoch 0/200] [Batch 163/938] [D loss: 0.092963] [G loss: 0.589903]\n",
      "[Epoch 0/200] [Batch 164/938] [D loss: 0.102508] [G loss: 0.393764]\n",
      "[Epoch 0/200] [Batch 165/938] [D loss: 0.102686] [G loss: 0.641328]\n",
      "[Epoch 0/200] [Batch 166/938] [D loss: 0.099823] [G loss: 0.516887]\n",
      "[Epoch 0/200] [Batch 167/938] [D loss: 0.089904] [G loss: 0.514953]\n",
      "[Epoch 0/200] [Batch 168/938] [D loss: 0.101760] [G loss: 0.648056]\n",
      "[Epoch 0/200] [Batch 169/938] [D loss: 0.170646] [G loss: 0.200124]\n",
      "[Epoch 0/200] [Batch 170/938] [D loss: 0.359746] [G loss: 1.360883]\n",
      "[Epoch 0/200] [Batch 171/938] [D loss: 0.667724] [G loss: 0.026678]\n",
      "[Epoch 0/200] [Batch 172/938] [D loss: 0.189606] [G loss: 0.351562]\n",
      "[Epoch 0/200] [Batch 173/938] [D loss: 0.219527] [G loss: 0.667552]\n",
      "[Epoch 0/200] [Batch 174/938] [D loss: 0.196987] [G loss: 0.562555]\n",
      "[Epoch 0/200] [Batch 175/938] [D loss: 0.184827] [G loss: 0.385551]\n",
      "[Epoch 0/200] [Batch 176/938] [D loss: 0.169968] [G loss: 0.295835]\n",
      "[Epoch 0/200] [Batch 177/938] [D loss: 0.174994] [G loss: 0.313705]\n",
      "[Epoch 0/200] [Batch 178/938] [D loss: 0.146798] [G loss: 0.396701]\n",
      "[Epoch 0/200] [Batch 179/938] [D loss: 0.140535] [G loss: 0.452543]\n",
      "[Epoch 0/200] [Batch 180/938] [D loss: 0.144397] [G loss: 0.375994]\n",
      "[Epoch 0/200] [Batch 181/938] [D loss: 0.136960] [G loss: 0.348961]\n",
      "[Epoch 0/200] [Batch 182/938] [D loss: 0.151738] [G loss: 0.401596]\n",
      "[Epoch 0/200] [Batch 183/938] [D loss: 0.143606] [G loss: 0.434047]\n",
      "[Epoch 0/200] [Batch 184/938] [D loss: 0.144857] [G loss: 0.399056]\n",
      "[Epoch 0/200] [Batch 185/938] [D loss: 0.148367] [G loss: 0.375115]\n",
      "[Epoch 0/200] [Batch 186/938] [D loss: 0.135010] [G loss: 0.425711]\n",
      "[Epoch 0/200] [Batch 187/938] [D loss: 0.129829] [G loss: 0.462223]\n",
      "[Epoch 0/200] [Batch 188/938] [D loss: 0.119407] [G loss: 0.422925]\n",
      "[Epoch 0/200] [Batch 189/938] [D loss: 0.100746] [G loss: 0.537153]\n",
      "[Epoch 0/200] [Batch 190/938] [D loss: 0.121692] [G loss: 0.424000]\n",
      "[Epoch 0/200] [Batch 191/938] [D loss: 0.116607] [G loss: 0.745188]\n",
      "[Epoch 0/200] [Batch 192/938] [D loss: 0.183945] [G loss: 0.192505]\n",
      "[Epoch 0/200] [Batch 193/938] [D loss: 0.306562] [G loss: 1.225371]\n",
      "[Epoch 0/200] [Batch 194/938] [D loss: 0.273717] [G loss: 0.091543]\n",
      "[Epoch 0/200] [Batch 195/938] [D loss: 0.147161] [G loss: 0.424465]\n",
      "[Epoch 0/200] [Batch 196/938] [D loss: 0.177749] [G loss: 0.556735]\n",
      "[Epoch 0/200] [Batch 197/938] [D loss: 0.158822] [G loss: 0.377983]\n",
      "[Epoch 0/200] [Batch 198/938] [D loss: 0.155622] [G loss: 0.317513]\n",
      "[Epoch 0/200] [Batch 199/938] [D loss: 0.140032] [G loss: 0.460847]\n",
      "[Epoch 0/200] [Batch 200/938] [D loss: 0.144539] [G loss: 0.451778]\n",
      "[Epoch 0/200] [Batch 201/938] [D loss: 0.127025] [G loss: 0.441610]\n",
      "[Epoch 0/200] [Batch 202/938] [D loss: 0.134242] [G loss: 0.431872]\n",
      "[Epoch 0/200] [Batch 203/938] [D loss: 0.145474] [G loss: 0.462174]\n",
      "[Epoch 0/200] [Batch 204/938] [D loss: 0.135899] [G loss: 0.430603]\n",
      "[Epoch 0/200] [Batch 205/938] [D loss: 0.120660] [G loss: 0.460678]\n",
      "[Epoch 0/200] [Batch 206/938] [D loss: 0.128236] [G loss: 0.593375]\n",
      "[Epoch 0/200] [Batch 207/938] [D loss: 0.173496] [G loss: 0.259715]\n",
      "[Epoch 0/200] [Batch 208/938] [D loss: 0.210423] [G loss: 1.005755]\n",
      "[Epoch 0/200] [Batch 209/938] [D loss: 0.208555] [G loss: 0.144591]\n",
      "[Epoch 0/200] [Batch 210/938] [D loss: 0.117202] [G loss: 0.594090]\n",
      "[Epoch 0/200] [Batch 211/938] [D loss: 0.090200] [G loss: 0.693205]\n",
      "[Epoch 0/200] [Batch 212/938] [D loss: 0.086997] [G loss: 0.477859]\n",
      "[Epoch 0/200] [Batch 213/938] [D loss: 0.066925] [G loss: 0.576818]\n",
      "[Epoch 0/200] [Batch 214/938] [D loss: 0.074547] [G loss: 0.708577]\n",
      "[Epoch 0/200] [Batch 215/938] [D loss: 0.086847] [G loss: 0.567272]\n",
      "[Epoch 0/200] [Batch 216/938] [D loss: 0.082562] [G loss: 0.511730]\n",
      "[Epoch 0/200] [Batch 217/938] [D loss: 0.106908] [G loss: 0.647941]\n",
      "[Epoch 0/200] [Batch 218/938] [D loss: 0.180280] [G loss: 0.228056]\n",
      "[Epoch 0/200] [Batch 219/938] [D loss: 0.195393] [G loss: 0.823289]\n",
      "[Epoch 0/200] [Batch 220/938] [D loss: 0.221828] [G loss: 0.142569]\n",
      "[Epoch 0/200] [Batch 221/938] [D loss: 0.185177] [G loss: 0.672492]\n",
      "[Epoch 0/200] [Batch 222/938] [D loss: 0.123508] [G loss: 0.421039]\n",
      "[Epoch 0/200] [Batch 223/938] [D loss: 0.103485] [G loss: 0.446212]\n",
      "[Epoch 0/200] [Batch 224/938] [D loss: 0.092756] [G loss: 0.680618]\n",
      "[Epoch 0/200] [Batch 225/938] [D loss: 0.079338] [G loss: 0.528380]\n",
      "[Epoch 0/200] [Batch 226/938] [D loss: 0.059018] [G loss: 0.672027]\n",
      "[Epoch 0/200] [Batch 227/938] [D loss: 0.067602] [G loss: 0.560037]\n",
      "[Epoch 0/200] [Batch 228/938] [D loss: 0.084022] [G loss: 0.796671]\n",
      "[Epoch 0/200] [Batch 229/938] [D loss: 0.188525] [G loss: 0.197179]\n",
      "[Epoch 0/200] [Batch 230/938] [D loss: 0.457921] [G loss: 1.593850]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-66782726ba2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import flycatcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mflycatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macgan\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAuxillaryClassifierGAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# from flycatcher.models.acgan import AuxillaryClassifierGAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# import torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# import torchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Repos\\GitHub\\source\\flycatcher\\flycatcher\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mflycatcher\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"v0.0.1a\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"flycatcher\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Repos\\GitHub\\source\\flycatcher\\flycatcher\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcGAN\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcGAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mACGAN\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAuxillaryClassifierGAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Repos\\GitHub\\source\\flycatcher\\flycatcher\\models\\cGAN\\cGAN.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Generate a batch of images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mgen_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# Loss measures generator's ability to fool the discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Repos\\GitHub\\source\\flycatcher\\flycatcher\\models\\cGAN\\cGAN.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, noise, labels)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# Concatenate label embedding and image to produce input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mgen_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2012\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2014\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2016\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import flycatcher\n",
    "from flycatcher.models.acgan import AuxillaryClassifierGAN\n",
    "# from flycatcher.models.acgan import AuxillaryClassifierGAN\n",
    "import torch\n",
    "import torchvision\n",
    "if __name__ == '__main__':\n",
    "    acgan_model = AuxillaryClassifierGAN()\n",
    "    acgan_model.train()\n",
    "    # print(torch.__version__)\n",
    "    # print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "nteract-on-jupyter@2.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
